{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8674647,"sourceType":"datasetVersion","datasetId":5199413}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Install các thư viện :**","metadata":{}},{"cell_type":"code","source":"!pip install accelerate>=0.21.0,<0.23.0  \n!pip install appdirs\n!pip install bitsandbytes>=0.41.1\n!pip install datasets\n!pip install fire\n!pip install gradio\n!pip install loralib\n!pip install peft\n!pip install sentencepiece\n!pip install scipy\n!pip install transformers\n!pip install torch \n!pip install requests","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:20:24.033867Z","iopub.execute_input":"2024-06-12T16:20:24.034283Z","iopub.status.idle":"2024-06-12T16:24:03.993106Z","shell.execute_reply.started":"2024-06-12T16:20:24.034248Z","shell.execute_reply":"2024-06-12T16:24:03.992155Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/bin/bash: 0.23.0: No such file or directory\nRequirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (1.4.4)\nCollecting black\n  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black) (8.1.7)\nRequirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from black) (1.0.0)\nCollecting packaging>=22.0 (from black)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nCollecting pathspec>=0.9.0 (from black)\n  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.10/site-packages (from black) (3.11.0)\nRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from black) (2.0.1)\nRequirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from black) (4.9.0)\nDownloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\nInstalling collected packages: pathspec, packaging, black\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\nkeras-nlp 0.12.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed black-24.4.2 packaging-24.1 pathspec-0.12.1\nRequirement already satisfied: black[jupyter] in /opt/conda/lib/python3.10/site-packages (24.4.2)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black[jupyter]) (8.1.7)\nRequirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from black[jupyter]) (1.0.0)\nRequirement already satisfied: packaging>=22.0 in /opt/conda/lib/python3.10/site-packages (from black[jupyter]) (24.1)\nRequirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from black[jupyter]) (0.12.1)\nRequirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.10/site-packages (from black[jupyter]) (3.11.0)\nRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from black[jupyter]) (2.0.1)\nRequirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from black[jupyter]) (4.9.0)\nRequirement already satisfied: ipython>=7.8.0 in /opt/conda/lib/python3.10/site-packages (from black[jupyter]) (8.20.0)\nCollecting tokenize-rt>=3.2.0 (from black[jupyter])\n  Downloading tokenize_rt-5.2.0-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]) (0.1.6)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]) (3.0.42)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]) (2.17.2)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]) (0.6.2)\nRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]) (5.9.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black[jupyter]) (4.8.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.8.0->black[jupyter]) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.8.0->black[jupyter]) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.8.0->black[jupyter]) (0.2.13)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.8.0->black[jupyter]) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.8.0->black[jupyter]) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.8.0->black[jupyter]) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=7.8.0->black[jupyter]) (1.16.0)\nDownloading tokenize_rt-5.2.0-py2.py3-none-any.whl (5.8 kB)\nInstalling collected packages: tokenize-rt\nSuccessfully installed tokenize-rt-5.2.0\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting fire\n  Downloading fire-0.6.0.tar.gz (88 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire) (2.4.0)\nBuilding wheels for collected packages: fire\n  Building wheel for fire (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117031 sha256=fa7b9f5da445a54382a51162888bdddcfca5c3335dbe2ce6df4d85d7d1e27873\n  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\nSuccessfully built fire\nInstalling collected packages: fire\nSuccessfully installed fire-0.6.0\nCollecting gradio\n  Downloading gradio-4.36.1-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.3.0)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.108.0)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio-client==1.0.1 (from gradio)\n  Downloading gradio_client-1.0.1-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\nRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.23.2)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.1.1)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.5)\nRequirement already satisfied: numpy<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.9.10)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (24.1)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.1)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (9.5.0)\nRequirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.5.3)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.9 (from gradio)\n  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0.1)\nCollecting ruff>=0.2.2 (from gradio)\n  Downloading ruff-0.4.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting tomlkit==0.12.0 (from gradio)\n  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\nCollecting typer<1.0,>=0.12 (from gradio)\n  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.9.0)\nCollecting urllib3~=2.0 (from gradio)\n  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.0.1->gradio) (2024.3.1)\nCollecting websockets<12.0,>=10.0 (from gradio-client==1.0.1->gradio)\n  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.14.6)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.0)\nRequirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.32.0.post1)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.16.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-4.36.1-py3-none-any.whl (12.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.0.1-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\nDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\nDownloading ruff-0.4.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: ffmpy\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=6bdf9c5a521ecaae4edb8fc51acea6f80fd24c1f5df590f5e951eafe3dc4a4d5\n  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\nSuccessfully built ffmpy\nInstalling collected packages: ffmpy, websockets, urllib3, tomlkit, semantic-version, ruff, python-multipart, typer, gradio-client, gradio\n  Attempting uninstall: websockets\n    Found existing installation: websockets 12.0\n    Uninstalling websockets-12.0:\n      Successfully uninstalled websockets-12.0\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: tomlkit\n    Found existing installation: tomlkit 0.12.5\n    Uninstalling tomlkit-0.12.5:\n      Successfully uninstalled tomlkit-0.12.5\n  Attempting uninstall: typer\n    Found existing installation: typer 0.9.0\n    Uninstalling typer-0.9.0:\n      Successfully uninstalled typer-0.9.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\nspacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nweasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ffmpy-0.3.2 gradio-4.36.1 gradio-client-1.0.1 python-multipart-0.0.9 ruff-0.4.8 semantic-version-2.10.0 tomlkit-0.12.0 typer-0.12.3 urllib3-2.1.0 websockets-11.0.3\nCollecting loralib\n  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\nDownloading loralib-0.1.2-py3-none-any.whl (10 kB)\nInstalling collected packages: loralib\nSuccessfully installed loralib-0.1.2\nCollecting peft\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (24.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.41.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.30.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.11.1\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.11.4)\nRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy) (1.26.4)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n\u001b[31mERROR: Invalid requirement: '=='\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Invalid requirement: '=='\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nCollecting args\n  Downloading args-0.1.0.tar.gz (3.0 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: args\n  Building wheel for args (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for args: filename=args-0.1.0-py3-none-any.whl size=3318 sha256=c4832b32edd6e53b69baffb78546b5f3106a3303a0158ba613c48c3b87e35a4f\n  Stored in directory: /root/.cache/pip/wheels/18/d7/bc/7b88d8405d97070a1a62712fd639ea0ad8d14b3dd74075cca6\nSuccessfully built args\nInstalling collected packages: args\nSuccessfully installed args-0.1.0\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Import thư viện :**","metadata":{}},{"cell_type":"code","source":"import json\nimport os.path as osp\nfrom typing import Union\nimport os\nimport sys\nfrom typing import List\n\nimport fire\nimport torch\nimport transformers\nfrom datasets import load_dataset\n\nfrom peft import (\n    LoraConfig,\n    get_peft_model,\n    set_peft_model_state_dict,\n)\nfrom transformers import LlamaForCausalLM, LlamaTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:24:03.995636Z","iopub.execute_input":"2024-06-12T16:24:03.996083Z","iopub.status.idle":"2024-06-12T16:24:11.515516Z","shell.execute_reply.started":"2024-06-12T16:24:03.996035Z","shell.execute_reply":"2024-06-12T16:24:11.514772Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Path : \npath_data_train_model = '/kaggle/input/data-nlp/Data_train/training_data.jsonl'\npath_template = '/kaggle/input/data-nlp/Data_train/templates/alpaca.json'\npath_output = 'ODIE_7b'","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:24:11.516706Z","iopub.execute_input":"2024-06-12T16:24:11.517273Z","iopub.status.idle":"2024-06-12T16:24:11.522047Z","shell.execute_reply.started":"2024-06-12T16:24:11.517239Z","shell.execute_reply":"2024-06-12T16:24:11.521109Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **Prompter :**","metadata":{}},{"cell_type":"code","source":"\"\"\"\nA dedicated helper to manage templates and prompt building.\n\"\"\"\nclass Prompter():\n    __slots__ = (\"template\", \"_verbose\")\n\n    def __init__(self, verbose: bool = False):\n        self._verbose = verbose\n        \n        #Read template and set it : \n        with open(path_template) as fp:\n            self.template = json.load(fp)\n        if self._verbose:\n            print(\n                f\"Using prompt template {template_name}: {self.template['description']}\"\n            )\n\n    def generate_prompt(\n        self,\n        instruction: str,\n        input: Union[None, str] = None,\n        label: Union[None, str] = None,\n    ) -> str:\n        \n        if input:\n            res = self.template[\"prompt_input\"].format(\n                instruction=instruction, input=input\n            )\n        else:\n            res = self.template[\"prompt_no_input\"].format(\n                instruction=instruction\n            )\n        if label:\n            res = f\"{res}{label}\"\n        if self._verbose:\n            print(res)\n        return res\n    \n    def generate_chat_prompt(\n        self,\n        messages: Union[None, str] = None,\n    ) -> str:\n        if len(messages) == 0:\n            raise ValueError('Messages field is empty.')\n\n        message_text = \"\"\n        for message in messages:\n            if message[\"role\"] == \"system\":\n                message_text += \"<|system|>\\n\" + message[\"content\"].strip() + \"\\n\\n\"\n            elif message[\"role\"] == \"user\":\n                message_text += \"<|user|>\\n\" + message[\"content\"].strip() + \"\\n\\n\"\n            elif message[\"role\"] == \"assistant\":\n                message_text += \"<|assistant|>\\n\" + message[\"content\"].strip() + \"\\n\\n\"\n            else:\n                raise ValueError(\"Invalid role: {}\".format(message[\"role\"]))\n        return message_text\n\n    def get_response(self, output: str, use_chat_prompt=False) -> str:\n        if use_chat_prompt:\n            return output.split('<|assistant|>\\n')[-1].strip()\n        else:\n            return output.split(self.template[\"response_split\"])[1].strip()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:24:11.524812Z","iopub.execute_input":"2024-06-12T16:24:11.525214Z","iopub.status.idle":"2024-06-12T16:24:11.538772Z","shell.execute_reply.started":"2024-06-12T16:24:11.525182Z","shell.execute_reply":"2024-06-12T16:24:11.538026Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def train(\n    # model/data params :\n    base_model: str = \"elinas/llama-7b-hf-transformers-4.29\",  # the only required argument\n    data_path: str = path_data_train_model,\n    output_dir: str = path_output,\n    #training hyperparams :\n    batch_size: int = 64,\n    micro_batch_size: int = 4,\n    num_epochs: int = 3,\n    learning_rate: float = 3e-4,\n    cutoff_len: int = 2048,\n    val_set_size: int = 1000,\n    #lora hyperparams :\n    lora_r: int = 16,\n    lora_alpha: int = 16,\n    lora_dropout: float = 0.05,\n    lora_target_modules: List[str] = [\n        \"q_proj\",\"v_proj\",\"k_proj\",\"o_proj\",\"up_proj\",\n        \"down_proj\",\"gate_proj\",\"embed_tokens\",\"lm_head\"\n    ],\n    #llm hyperparams :\n    train_on_inputs: bool = False,  #if False, masks out inputs in loss\n    add_eos_token: bool = False,\n    group_by_length: bool = False,  #faster, but produces an odd training loss curve\n    resume_from_checkpoint: str = None,\n    use_chat_prompt: bool = False, # whether to use the prompt for multi-turn conversation\n    prompt_template_name: str = \"Alpaca\"\n   \n):\n    print(\n        f\"Training Alpaca-LoRA model with params:\\n\"\n        f\"base_model: {base_model}\\n\"\n        f\"data_path: {data_path}\\n\"\n        f\"output_dir: {output_dir}\\n\"\n        f\"batch_size: {batch_size}\\n\"\n        f\"micro_batch_size: {micro_batch_size}\\n\"\n        f\"num_epochs: {num_epochs}\\n\"\n        f\"learning_rate: {learning_rate}\\n\"\n        f\"cutoff_len: {cutoff_len}\\n\"\n        f\"val_set_size: {val_set_size}\\n\"\n        f\"lora_r: {lora_r}\\n\"\n        f\"lora_alpha: {lora_alpha}\\n\"\n        f\"lora_dropout: {lora_dropout}\\n\"\n        f\"lora_target_modules: {lora_target_modules}\\n\"\n        f\"train_on_inputs: {train_on_inputs}\\n\"\n        f\"add_eos_token: {add_eos_token}\\n\"\n        f\"group_by_length: {group_by_length}\\n\"\n        f\"resume_from_checkpoint: {resume_from_checkpoint or False}\\n\"\n        f\"prompt template: {prompt_template_name}\\n\"\n    )\n    \n    gradient_accumulation_steps = batch_size // micro_batch_size\n    \n    prompter = Prompter()\n\n    model = LlamaForCausalLM.from_pretrained(\n        base_model,\n        load_in_8bit=False,\n        torch_dtype=torch.float16,\n    )\n\n    tokenizer = LlamaTokenizer.from_pretrained(base_model,legacy=False)\n\n    tokenizer.pad_token_id = (\n        0  # unk. we want this to be different from the eos token\n    )\n    tokenizer.padding_side = \"left\"  # Allow batched inference\n\n    def tokenize(prompt, add_eos_token=True):\n        result = tokenizer(\n            prompt,\n            truncation=True,\n            max_length=cutoff_len,\n            padding=False,\n            return_tensors=None,\n        )\n        if (\n            result[\"input_ids\"][-1] != tokenizer.eos_token_id\n            and len(result[\"input_ids\"]) < cutoff_len\n            and add_eos_token\n        ):\n            result[\"input_ids\"].append(tokenizer.eos_token_id)\n            result[\"attention_mask\"].append(1)\n\n        result[\"labels\"] = result[\"input_ids\"].copy()\n\n        return result\n\n    def generate_and_tokenize_prompt(data_point):\n        if use_chat_prompt:\n            assert \"messages\" in data_point\n            full_prompt = prompter.generate_chat_prompt(\n                data_point[\"messages\"]\n            )\n        else:\n            full_prompt = prompter.generate_prompt(\n                            data_point[\"instruction\"], #Instruction\n                            data_point[\"text\"], #Input \n                            data_point[\"table\"], #Output\n                            )\n        tokenized_full_prompt = tokenize(full_prompt)\n        \n        if not train_on_inputs:\n            if use_chat_prompt:\n                user_prompt = prompter.generate_chat_prompt(\n                    data_point[\"messages\"][:-1]\n                )\n                user_prompt += \"<|assistant|>\\n\"\n            else:\n                user_prompt = prompter.generate_prompt(\n                    data_point[\"instruction\"], \n                    data_point[\"input\"]\n                )\n            \n            tokenized_user_prompt = tokenize(\n                user_prompt, add_eos_token=add_eos_token\n            )\n            user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n\n            if add_eos_token:\n                user_prompt_len -= 1\n\n            tokenized_full_prompt[\"labels\"] = [\n                -100\n            ] * user_prompt_len + tokenized_full_prompt[\"labels\"][\n                user_prompt_len:\n            ]  # could be sped up, probably\n\n        return tokenized_full_prompt\n    \n    # For int8\n    # model = prepare_model_for_int8_training(model)\n\n    config = LoraConfig(\n        r=lora_r,\n        lora_alpha=lora_alpha,\n        target_modules=lora_target_modules,\n        lora_dropout=lora_dropout,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\",\n    )\n    model = get_peft_model(model, config)\n\n    if data_path.endswith(\".json\") or data_path.endswith(\".jsonl\"):\n        data = load_dataset(\"json\", data_files=data_path)\n    else:\n        data = load_dataset(data_path)\n    \n#     #Checkpoints :\n#     if resume_from_checkpoint:\n#         # Check the available weights and load them\n#         checkpoint_name = os.path.join(\n#             resume_from_checkpoint, \"pytorch_model.bin\"\n#         )  # Full checkpoint\n#         if not os.path.exists(checkpoint_name):\n#             checkpoint_name = os.path.join(\n#                 resume_from_checkpoint, \"adapter_model.bin\"\n#             )  # only LoRA model - LoRA config above has to fit\n#             resume_from_checkpoint = (\n#                 False  # So the trainer won't try loading its state\n#             )\n#         # The two files above have a different name depending on how they were saved, but are actually the same.\n#         if os.path.exists(checkpoint_name):\n#             print(f\"Restarting from {checkpoint_name}\")\n#             adapters_weights = torch.load(checkpoint_name)\n#             set_peft_model_state_dict(model, adapters_weights)\n#         else:\n#             print(f\"Checkpoint {checkpoint_name} not found\")\n\n    model.print_trainable_parameters()  # Be more transparent about the % of trainable params.\n\n    #Split data : \n    if val_set_size > 0:\n        train_val = data[\"train\"].train_test_split(\n            test_size=val_set_size, shuffle=True, seed=42\n        )\n        train_data = (\n            train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n        )\n        val_data = (\n            train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)\n        )\n    else:\n        train_data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n        val_data = None\n\n    #Compile Model : \n    trainer = transformers.Trainer(\n        model=model,\n        train_dataset=train_data,\n        eval_dataset=val_data,\n        args=transformers.TrainingArguments(\n            per_device_train_batch_size=micro_batch_size,\n            per_device_eval_batch_size=micro_batch_size,\n            gradient_accumulation_steps=gradient_accumulation_steps,\n            warmup_ratio=0.03,\n            num_train_epochs=num_epochs,\n            learning_rate=learning_rate,\n            fp16=False,\n            logging_steps=10,\n            optim=\"adamw_torch\",\n            save_strategy=\"epoch\", #lưu checkpoint theo từng epoch\n            eval_strategy=\"epoch\" if val_set_size > 0 else \"no\",\n            output_dir=output_dir,\n            save_total_limit=10, #Giới hạn số lượng checkpoint được lưu.\n            load_best_model_at_end=True if val_set_size > 0 else False,\n            group_by_length=group_by_length,\n            gradient_checkpointing=True,\n        ),\n        data_collator=transformers.DataCollatorForSeq2Seq(\n            tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n        ),\n    )\n    model.config.use_cache = False\n    \n    #Training Model :\n    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n\n    model.save_pretrained(output_dir)\n    \n    print('Completion Training !')","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:24:11.540169Z","iopub.execute_input":"2024-06-12T16:24:11.540592Z","iopub.status.idle":"2024-06-12T16:24:11.567571Z","shell.execute_reply.started":"2024-06-12T16:24:11.540549Z","shell.execute_reply":"2024-06-12T16:24:11.566602Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"fire.Fire(train)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:24:11.568681Z","iopub.execute_input":"2024-06-12T16:24:11.569023Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Training Alpaca-LoRA model with params:\nbase_model: huggyllama/llama-7b\ndata_path: yahma/alpaca-cleaned\noutput_dir: /kaggle/working/OutputModel\nbatch_size: 128\nmicro_batch_size: 4\nnum_epochs: 3\nlearning_rate: 0.0003\ncutoff_len: 256\nval_set_size: 2000\nlora_r: 8\nlora_alpha: 16\nlora_dropout: 0.05\nlora_target_modules: ['q_proj', 'v_proj', 'k_proj', 'o_proj', 'up_proj', 'down_proj', 'gate_proj', 'embed_tokens', 'lm_head']\ntrain_on_inputs: True\nadd_eos_token: False\ngroup_by_length: False\nresume_from_checkpoint: False\nprompt template: Alpaca\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/594 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f50b0449d8e40a7ae8a0ce6af7d0ef0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cb476b6beaf411eb8550fdbf12e7f3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a3a1efed9ae435fa608554dc4df121b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f71b84d70aa548479351f6381a3c5324"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c16b87419a4e49cd90806e921906a291"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"016e321f5e8142a5b3d84d4adf515252"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18219dc55a3f4e9aaf29f24babc2a539"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/700 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"feaef14b87404598829ef7b2860de78c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"667cc10a8bf7439d9e8ccbf4b86cf0f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1826ffc15c7941b98cafdfe5f87d1983"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ca3cc11782047188efa13b4cf14fc5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/11.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"985b2da694b54f58be3e3eeec6469fe6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/44.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43c84897e0fe4bccad56fde3b6937061"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2ea4ed2e4c743e8a387ed38ab66fbeb"}},"metadata":{}},{"name":"stdout","text":"trainable params: 20,566,016 || all params: 6,758,981,632 || trainable%: 0.3043\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/49760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5526a8820d2a4f5d9714454fbe971c3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d475a96a4be14e6ebfc09ba3846a0693"}},"metadata":{}},{"name":"stderr","text":"2024-06-12 16:27:51.164261: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-12 16:27:51.164407: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-12 16:27:51.303071: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011115984177777389, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"463597e9b4e0458c934a6fb187e52c0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240612_162821-1a07qku2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/huflit/huggingface/runs/1a07qku2' target=\"_blank\">/kaggle/working/OutputModel</a></strong> to <a href='https://wandb.ai/huflit/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/huflit/huggingface' target=\"_blank\">https://wandb.ai/huflit/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/huflit/huggingface/runs/1a07qku2' target=\"_blank\">https://wandb.ai/huflit/huggingface/runs/1a07qku2</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4' max='1164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   4/1164 06:33 < 63:27:24, 0.01 it/s, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]}]}